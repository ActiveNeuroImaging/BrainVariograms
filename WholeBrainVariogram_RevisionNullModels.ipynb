{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea786073",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Load surface mask and distance matrix\n",
    "\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "from brainspace.gradient import GradientMaps\n",
    "from brainspace.gradient import alignment\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.decomposition import PCA\n",
    "import helpers\n",
    "\n",
    "HCPFilenamesList = glob.glob('../IndSubHCP/*.mat')\n",
    "HCPFilenamesList.sort()\n",
    "SurfaceMask=np.loadtxt('surfBilateralMask.txt')\n",
    "\n",
    "numFiles=len(HCPFilenamesList)\n",
    "numV_l=np.count_nonzero(SurfaceMask[:5000])\n",
    "numV_l=np.count_nonzero(SurfaceMask[5000:])\n",
    "\n",
    "num_bins=20\n",
    "dist_mat_file = \"SurfL10kConte.txt\"\n",
    "\n",
    "dist_file=np.loadtxt(dist_mat_file)\n",
    "\n",
    "dist_file_masked=dist_file[np.ix_(SurfaceMask[:5000]==1,SurfaceMask[:5000]==1)]\n",
    "\n",
    "dist_file_masked=dist_file[np.ix_(SurfaceMask[:5000]==1,SurfaceMask[:5000]==1)]\n",
    "reduceIndices=np.ix_(np.arange(0,dist_file_masked.shape[0],10),np.arange(0,dist_file_masked.shape[0],10))\n",
    "dist_file_masked_reduced=dist_file_masked[reduceIndices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c019d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decimate the data to make the smoothing/resampling step computationally tractable on laptop\n",
    "reduceIndices=np.ix_(np.arange(0,dist_file_masked.shape[0],10),np.arange(0,dist_file_masked.shape[0],10))\n",
    "dist_file_masked_reduced=dist_file_masked[reduceIndices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad9ffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Load individual FMRI data on surface and calculate group variogram\n",
    "\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "from brainspace.gradient import GradientMaps\n",
    "from brainspace.gradient import alignment\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.decomposition import PCA\n",
    "import helpers\n",
    "\n",
    "HCPFilenamesList = glob.glob('../IndSubHCP/*.mat')\n",
    "HCPFilenamesList.sort()\n",
    "SurfaceMask=np.loadtxt('surfBilateralMask.txt')\n",
    "\n",
    "numFiles=len(HCPFilenamesList)\n",
    "numV_l=np.count_nonzero(SurfaceMask[:5000])\n",
    "numV_l=np.count_nonzero(SurfaceMask[5000:])\n",
    "\n",
    "num_bins=20\n",
    "dist_mat_file = \"SurfL10kConte.txt\"\n",
    "dist_mat_file_r = \"SurfR10kConte.txt\"\n",
    "dist_file=np.loadtxt(dist_mat_file)\n",
    "dist_file_r=np.loadtxt(dist_mat_file_r)\n",
    "dist_file_masked=dist_file[np.ix_(SurfaceMask[:5000]==1,SurfaceMask[:5000]==1)]\n",
    "dist_file_masked_r=dist_file_r[np.ix_(SurfaceMask[5000:]==1,SurfaceMask[5000:]==1)]\n",
    "\n",
    "\n",
    "FC_l=np.zeros([dist_file_masked.shape[0],dist_file_masked.shape[0]])\n",
    "FC_r=np.zeros([dist_file_masked_r.shape[0],dist_file_masked_r.shape[0]])\n",
    "ind_fc_ev_l=np.zeros([numFiles,num_bins])\n",
    "ind_fc_h_l=np.zeros([numFiles,num_bins])\n",
    "ind_fc_ev_r=np.zeros([numFiles,num_bins])\n",
    "ind_fc_h_r=np.zeros([numFiles,num_bins])\n",
    "ind_fc_ev_l_2=np.zeros([numFiles,num_bins])\n",
    "ind_fc_h_l_2=np.zeros([numFiles,num_bins])\n",
    "ind_fc_ev_r_2=np.zeros([numFiles,num_bins])\n",
    "ind_fc_h_r_2=np.zeros([numFiles,num_bins])\n",
    "\n",
    "for i,dataName in enumerate(HCPFilenamesList):\n",
    "\n",
    "\n",
    "\n",
    "    print(dataName)\n",
    "    f = h5py.File(dataName)\n",
    "    arrays = {}\n",
    "    for k, v in f.items():\n",
    "        arrays[k] = np.array(v)\n",
    "\n",
    "    IndData1=arrays['rfMRI_REST1_LR']\n",
    "    \n",
    "    tempData=IndData1[:5000,:]\n",
    "    tempDataReduced=tempData[SurfaceMask[:5000]==1,:]\n",
    "    tempFC=np.corrcoef(tempDataReduced)\n",
    "    ind_fc_h_l[i,:],ind_fc_ev_l[i,:]=helpers.emp_variogram_conn(tempFC,dist_file_masked,num_bins,[0,150])\n",
    "    tempFC=np.arctanh(tempFC)\n",
    "    np.fill_diagonal(tempFC,3)\n",
    "    FC_l=FC_l+tempFC\n",
    "    \n",
    "    tempData=IndData1[5000:,:]\n",
    "    tempDataReduced=tempData[SurfaceMask[5000:]==1,:]\n",
    "    tempFC=np.corrcoef(tempDataReduced)\n",
    "    ind_fc_h_r[i,:],ind_fc_ev_r[i,:]=helpers.emp_variogram_conn(tempFC,dist_file_masked_r,num_bins,[0,150])\n",
    "    tempFC=np.arctanh(tempFC)\n",
    "    np.fill_diagonal(tempFC,3)\n",
    "    FC_r=FC_r+tempFC\n",
    "    \n",
    "    IndData1=arrays['rfMRI_REST1_RL']\n",
    "    tempData=IndData1[:5000,:]\n",
    "    tempDataReduced=tempData[SurfaceMask[:5000]==1,:]\n",
    "    tempFC=np.corrcoef(tempDataReduced)\n",
    "    ind_fc_h_l_2[i,:],ind_fc_ev_l_2[i,:]=helpers.emp_variogram_conn(tempFC,dist_file_masked,num_bins,[0,150])\n",
    "\n",
    "    \n",
    "    tempData=IndData1[5000:,:]\n",
    "    tempDataReduced=tempData[SurfaceMask[5000:]==1,:]\n",
    "    tempFC=np.corrcoef(tempDataReduced)\n",
    "    ind_fc_h_r_2[i,:],ind_fc_ev_r_2[i,:]=helpers.emp_variogram_conn(tempFC,dist_file_masked_r,num_bins,[0,150])\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "FC_l=FC_l/(numFiles+1)\n",
    "FC_l=np.tanh(FC_l)   \n",
    "\n",
    "FC_r=FC_r/(numFiles+1)\n",
    "FC_r=np.tanh(FC_r)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cbab46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample function\n",
    "def replace_corr_values(smoothed_corr, original_corr):\n",
    "    # Rank the values in the smoothed and original correlation matrices\n",
    "    smoothed_ranks = np.argsort(np.argsort(smoothed_corr, axis=None)).reshape(smoothed_corr.shape)\n",
    "    original_ranks = np.argsort(np.argsort(original_corr, axis=None)).reshape(original_corr.shape)\n",
    "    # Replace the values in the smoothed correlation matrix with values from the original correlation matrix based on rank\n",
    "    for row in range(smoothed_corr.shape[0]):\n",
    "        for col in range(row + 1, smoothed_corr.shape[1]):\n",
    "            if smoothed_corr[row, col] < 1.0:\n",
    "                smoothed_rank = smoothed_ranks[row, col]\n",
    "                original_ranked_values = original_corr[original_ranks == smoothed_rank]\n",
    "                original_ranked_values = original_ranked_values[original_ranked_values < 1.0]\n",
    "                if original_ranked_values.size > 0:\n",
    "                    original_value = original_ranked_values[-1]\n",
    "                    smoothed_corr[row, col] = original_value\n",
    "                    smoothed_corr[col, row] = original_value\n",
    "    # Set the diagonal elements to 1\n",
    "    np.fill_diagonal(smoothed_corr, 1)\n",
    "    return smoothed_corr\n",
    "\n",
    "# Gaussian smoothing function\n",
    "def smooth_corr(corr, dist, k=5, b=1.0,Resample=False):\n",
    "    # Sort distances and get indices of k-nearest neighbors\n",
    "    knn_indices = np.argsort(dist, axis=1)[:, :k]\n",
    "    # Compute weights for each edge using exponential kernel\n",
    "    weights = np.exp(-dist/dist.max() / b)\n",
    "    # Set weights to 0 for edges not in k-nearest neighbors\n",
    "    mask = np.zeros_like(weights)\n",
    "    mask[np.arange(len(mask))[:, None], knn_indices] = 1\n",
    "    weights *= mask\n",
    "    # Normalize weights for each node to sum to 1\n",
    "    row_sums = weights.sum(axis=1)\n",
    "    weights /= row_sums[:, np.newaxis]\n",
    "    # Compute smoothed correlation matrix\n",
    "    smoothed_corr = weights.dot(corr).dot(weights.T)\n",
    "\n",
    "    smoothed_corr = (smoothed_corr + smoothed_corr.T) / 2\n",
    "    np.fill_diagonal(smoothed_corr, smoothed_corr.max())\n",
    "    \n",
    "    if Resample:\n",
    "        smoothed_corr = replace_corr_values(smoothed_corr, corr)\n",
    "    return smoothed_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14638d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best smoothing parameters for null model to approximately fit empirical variogram\n",
    "\n",
    "from scipy import special\n",
    "from scipy.optimize import curve_fit\n",
    "import math\n",
    "h_l,wb_average_ev_l=helpers.emp_variogram_conn(EmpFC,dist_file_masked_reduced,num_bins,[0,150])\n",
    "\n",
    "\n",
    "EmpFC=FC_l[reduceIndices]\n",
    "mat=EmpFC\n",
    "nr = mat.shape[0] # number of regions\n",
    "mat_rand = np.zeros(mat.shape) # initialise number of regions\n",
    "mat_rand[np.triu_indices(nr,1)] = np.random.permutation(mat[np.triu_indices(nr,1)]) # permute upper triangular\n",
    "mat_rand = mat_rand+mat_rand.T # fill lower triangular\n",
    "mat_rand[np.diag_indices(nr)] = 1 # set diagonal to 1\n",
    "mantel_ind = np.random.permutation(nr) # indices to permute regions\n",
    "FC_mantel = mat[mantel_ind,:][:,mantel_ind] # apply to both rows and columns\n",
    "FC_mantel = (FC_mantel+FC_mantel.T)/2 # fill lower triangular\n",
    "\n",
    "\n",
    "cutoff=np.linspace(30,90,20,dtype=int)\n",
    "smooth=np.linspace(0.02,0.05,20)\n",
    "optSmooth=np.zeros([len(cutoff),len(smooth)])\n",
    "for i,cut in enumerate(cutoff):\n",
    "    for j, sm in enumerate(smooth):\n",
    "        mantel_ind = np.random.permutation(nr) # indices to permute regions\n",
    "        FC_mantel = mat[mantel_ind,:][:,mantel_ind] # apply to both rows and columns\n",
    "        FC_mantel = (FC_mantel+FC_mantel.T)/2 # fill lower triangular\n",
    "\n",
    "\n",
    "        smoothed_corr_mat=smooth_corr(FC_mantel,dist_file_masked_reduced,cut,sm,True)\n",
    "        h,Emp_vg=helpers.emp_variogram_conn(EmpFC,dist_file_masked_reduced,num_bins,[0,150])\n",
    "        h,vg=helpers.emp_variogram_conn(smoothed_corr_mat,dist_file_masked_reduced,num_bins,[0,150])\n",
    "        optSmooth[i,j]= np.power(np.power((vg-wb_average_ev_l),2).sum(),0.5)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e464c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take optimal parameters from above and generate 1000 Mantel shuffled, smoothed and resampled datasets\n",
    "\n",
    "reduceIndices=np.ix_(np.arange(0,dist_file_masked.shape[0],10),np.arange(0,dist_file_masked.shape[0],10))\n",
    "dist_file_masked_reduced=dist_file_masked[reduceIndices]\n",
    "EmpFC=FC_l[reduceIndices]\n",
    "\n",
    "mat=EmpFC.copy()\n",
    "\n",
    "\n",
    "nr = mat.shape[0] # number of regions\n",
    "h_l,wb_average_ev_l=helpers.emp_variogram_conn(EmpFC,dist_file_masked_reduced,num_bins,[0,150])\n",
    "\n",
    "perms=1000\n",
    "#AllVGRandSmoothed=np.zeros([wb_average_ev_l.shape[0],perms])\n",
    "AllMatRandUnsmoothed1=np.zeros([EmpFC.shape[0],EmpFC.shape[1],perms])\n",
    "AllMatRandUnsmoothed2=np.zeros([EmpFC.shape[0],EmpFC.shape[1],perms])\n",
    "#AllMatRandSmoothed=np.zeros([EmpFC.shape[0],EmpFC.shape[1],perms])\n",
    "\n",
    "#AllSmoothRegress_betas=np.zeros([2,perms])\n",
    "\n",
    "cut=45 # Parameters \n",
    "sm=0.03\n",
    "for i in range(perms):\n",
    "    if np.mod(i,20)==0:\n",
    "        print(i)\n",
    "    mat_rand = np.zeros(mat.shape) # initialise number of regions\n",
    "    mat_rand[np.triu_indices(nr,1)] = np.random.permutation(mat[np.triu_indices(nr,1)]) # permute upper triangular\n",
    "    mat_rand = mat_rand+mat_rand.T # fill lower triangular\n",
    "    mat_rand[np.diag_indices(nr)] = 1 # set diagonal to 1\n",
    "    mantel_ind = np.random.permutation(nr) # indices to permute regions\n",
    "    FC_mantel = mat[mantel_ind,:][:,mantel_ind] # apply to both rows and columns\n",
    "    FC_mantel = (FC_mantel+FC_mantel.T)/2 # fill lower triangular\n",
    "    FC_mantel[np.diag_indices(nr)] = 1 # set diagonal to 1\n",
    "    AllMatRandUnsmoothed1[:,:,i]=FC_mantel\n",
    "    AllMatRandUnsmoothed2[:,:,i]=mat_rand\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8a597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot different null model variograms and empirical variogram\n",
    "h,Emp_vg=helpers.emp_variogram_conn(EmpFC,dist_file_masked_reduced,num_bins,[0,150])\n",
    "h,vg=helpers.emp_variogram_conn(AllMatRandSmoothed[:,:,23],dist_file_masked_reduced,num_bins,[0,150])\n",
    "h,vgMant=helpers.emp_variogram_conn(FC_mantel,dist_file_masked_reduced,num_bins,[0,150])\n",
    "h,vgRand=helpers.emp_variogram_conn(mat_rand,dist_file_masked_reduced,num_bins,[0,150])\n",
    "\n",
    "\n",
    "fig=plt.figure(figsize=(8, 8))\n",
    "fig.patch.set_alpha(0)\n",
    "smoothing=0.5\n",
    "x=gaussian_filter1d(Emp_vg, sigma=smoothing)\n",
    "plt.plot(h, x, 'o',c='b',label='Empirical')\n",
    "x=gaussian_filter1d(vgRand, sigma=smoothing)\n",
    "plt.plot(h, x, '--',c='r',label='Random permutation')\n",
    "x=gaussian_filter1d(vgMant, sigma=smoothing)\n",
    "plt.plot(h, x, '--',c='k',label='Mantel permutation')\n",
    "x=gaussian_filter1d(vg, sigma=smoothing)\n",
    "plt.plot(h, x, '--',c='g',label='Mantel permutation followed by smoothing')\n",
    "plt.legend()\n",
    "plt.savefig('./imagesAvG/NullVariograms.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc20815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot example connectivity matrices\n",
    "\n",
    "fig, axs = plt.subplots(1,4,figsize=(16,4))\n",
    "fig.patch.set_alpha(0)\n",
    "\n",
    "#plt.imshow(AllMatRandSmoothed[:,:,23],interpolation='nearest')\n",
    "axs[0].imshow(EmpFC,interpolation='nearest',cmap=plt.cm.coolwarm,vmin=-0.5,vmax=0.5)\n",
    "axs[1].imshow(AllMatRandUnsmoothed2[:,:,1],interpolation='nearest',cmap=plt.cm.coolwarm,vmin=-0.5,vmax=0.5)\n",
    "axs[2].imshow(AllMatRandUnsmoothed1[:,:,1],interpolation='nearest',cmap=plt.cm.coolwarm,vmin=-0.5,vmax=0.5)\n",
    "axs[3].imshow(AllMatRandSmoothed[:,:,1],interpolation='nearest',cmap=plt.cm.coolwarm,vmin=-0.5,vmax=0.5)\n",
    "\n",
    "plt.savefig('./imagesAvG/NullFCs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d8c227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit theoretical variograms to different null models\n",
    "\n",
    "perms=1000\n",
    "\n",
    "US1ShuffModelPred_evVw_l=np.zeros([perms,evVw_l.shape[0],4,num_bins-3])\n",
    "US1ShuffModelSSE_evVw_l=np.zeros([perms,evVw_l.shape[0],4])\n",
    "US1ShuffModelCof_evVw_l=np.zeros([perms,evVw_l.shape[0],4,3])\n",
    "\n",
    "US2ShuffModelPred_evVw_l=np.zeros([perms,evVw_l.shape[0],4,num_bins-3])\n",
    "US2ShuffModelSSE_evVw_l=np.zeros([perms,evVw_l.shape[0],4])\n",
    "US2ShuffModelCof_evVw_l=np.zeros([perms,evVw_l.shape[0],4,3])\n",
    "\n",
    "\n",
    "for i in range(perms):\n",
    "    hVw_l,evVw_l=helpers.emp_variogram_vwise_conn(AllMatRandUnsmoothed1[:,:,i],dist_file_masked_reduced,num_bins,[0,150]) #vary last number for maximum range \n",
    "\n",
    "    for j in range(evVw_l.shape[0]):\n",
    "        y=evVw_l[j,clipStart:clipEnd]\n",
    "        x=hVw_l[j,clipStart:clipEnd]\n",
    "        bounds = (0.00001, [np.nanmax(x),np.nanmax(y),np.nanmax(y)/10])\n",
    "\n",
    "        cof = None\n",
    "        cov = None\n",
    "\n",
    "        for ind,model in enumerate(models):\n",
    "\n",
    "            cof, cov = curve_fit(model,x, y, method='trf',p0=bounds[1],bounds=bounds,maxfev=5000)\n",
    "            v_pred=model(x,*cof)\n",
    "            \n",
    "            US1ShuffModelPred_evVw_l[i,j,ind,:]=v_pred\n",
    "            US1ShuffModelSSE_evVw_l[i,j,ind]=np.sum((v_pred-y)**2)\n",
    "            US1ShuffModelCof_evVw_l[i,j,ind,:]=cof\n",
    "\n",
    "\n",
    "\n",
    "for i in range(perms):\n",
    "    hVw_l,evVw_l=helpers.emp_variogram_vwise_conn(AllMatRandUnsmoothed2[:,:,i],dist_file_masked_reduced,num_bins,[0,150]) #vary last number for maximum range \n",
    "\n",
    "    for j in range(evVw_l.shape[0]):\n",
    "        y=evVw_l[j,clipStart:clipEnd]\n",
    "        x=hVw_l[j,clipStart:clipEnd]\n",
    "        bounds = (0.00001, [np.nanmax(x),np.nanmax(y),np.nanmax(y)/10])\n",
    "\n",
    "        cof = None\n",
    "        cov = None\n",
    "\n",
    "        for ind,model in enumerate(models):\n",
    "\n",
    "            cof, cov = curve_fit(model,x, y, method='trf',p0=bounds[1],bounds=bounds,maxfev=5000)\n",
    "            v_pred=model(x,*cof)\n",
    "            US2ShuffModelPred_evVw_l[i,j,ind,:]=v_pred\n",
    "            US2ShuffModelSSE_evVw_l[i,j,ind]=np.sum((v_pred-y)**2)\n",
    "            US2ShuffModelCof_evVw_l[i,j,ind,:]=cof\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe94305b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot correlation of different null permutations with Principal gradient\n",
    "print(np.corrcoef(ModelCof_evVw_l[:,1,0],gml.gradients_[:,0])[0,1])\n",
    "print(np.corrcoef(ModelCof_evVw_l[:,1,1],gml.gradients_[:,0])[0,1])\n",
    "CorrGradRange=np.zeros([perms,3])\n",
    "CorrGradSill=np.zeros([perms,3])\n",
    "for i in range(perms):\n",
    "    CorrGradRange[i,2]=np.corrcoef(ShuffModelCof_evVw_l[i,:,1,0],gml.gradients_[:,0])[0,1]\n",
    "    CorrGradSill[i,2]=np.corrcoef(ShuffModelCof_evVw_l[i,:,1,1],gml.gradients_[:,0])[0,1]\n",
    "\n",
    "for i in range(perms):\n",
    "    CorrGradRange[i,1]=np.corrcoef(US1ShuffModelCof_evVw_l[i,:,1,0],gml.gradients_[:,0])[0,1]\n",
    "    CorrGradSill[i,1]=np.corrcoef(US1ShuffModelCof_evVw_l[i,:,1,1],gml.gradients_[:,0])[0,1]\n",
    "\n",
    "for i in range(perms):\n",
    "    CorrGradRange[i,0]=np.corrcoef(US2ShuffModelCof_evVw_l[i,:,1,0],gml.gradients_[:,0])[0,1]\n",
    "    CorrGradSill[i,0]=np.corrcoef(US2ShuffModelCof_evVw_l[i,:,1,1],gml.gradients_[:,0])[0,1]\n",
    "\n",
    "print('Corr Max')\n",
    "print('Range')\n",
    "print(CorrGradRange.max(axis=0))\n",
    "print('Sill')\n",
    "print(CorrGradSill.max(axis=0))\n",
    "\n",
    "print('Corr Std')\n",
    "\n",
    "print('Range')\n",
    "print(CorrGradRange.std(axis=0))\n",
    "print('Sill')\n",
    "print(CorrGradSill.std(axis=0))\n",
    "\n",
    "\n",
    "print('Real STD')\n",
    "print('Range')\n",
    "print(np.std(ModelCof_evVw_l[:,1,0],axis=0))\n",
    "print('Sill')\n",
    "print(np.std(ModelCof_evVw_l[:,1,1],axis=0))\n",
    "\n",
    "print('Std')\n",
    "print('Range')\n",
    "print(ShuffModelCof_evVw_l[:,:,1,0].std(axis=0).mean())\n",
    "print(US1ShuffModelCof_evVw_l[:,:,1,0].std(axis=0).mean())\n",
    "print(US2ShuffModelCof_evVw_l[:,:,1,0].std(axis=0).mean())\n",
    "print('Sill')\n",
    "print(ShuffModelCof_evVw_l[:,:,1,1].std(axis=0).mean())\n",
    "print(US1ShuffModelCof_evVw_l[:,:,1,1].std(axis=0).mean())\n",
    "print(US2ShuffModelCof_evVw_l[:,:,1,1].std(axis=0).mean())\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.patch.set_alpha(0)\n",
    "\n",
    "ax = fig.add_axes([0.1,0.1,0.9,0.9])\n",
    "bp = ax.violinplot(CorrGradRange)\n",
    "\n",
    "for pc in bp['bodies']:\n",
    "    pc.set_facecolor('white')\n",
    "    pc.set_edgecolor('black')\n",
    "    \n",
    "for partname in ('cbars','cmins','cmaxes'):\n",
    "    vp = bp[partname]\n",
    "    vp.set_edgecolor('k')\n",
    "    vp.set_linewidth(1)\n",
    "ax.axhline(np.corrcoef(ModelCof_evVw_l[:,1,0],gml.gradients_[:,0])[0,1],ls=\"--\", color=\"k\")\n",
    "\n",
    "ax.set_xticks([1, 2,3])\n",
    "ax.set_xticklabels([\"Random\",\"Mantel\",\"Smoothed Mantel\"])\n",
    "plt.savefig('./imagesAvG/NullCorrGradRange.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.patch.set_alpha(0)\n",
    "\n",
    "ax = fig.add_axes([0.1,0.1,0.9,0.9])\n",
    "bp = ax.violinplot(CorrGradSill)\n",
    "\n",
    "for pc in bp['bodies']:\n",
    "    pc.set_facecolor('white')\n",
    "    pc.set_edgecolor('black')\n",
    "    \n",
    "for partname in ('cbars','cmins','cmaxes'):\n",
    "    vp = bp[partname]\n",
    "    vp.set_edgecolor('k')\n",
    "    vp.set_linewidth(1)\n",
    "ax.axhline(np.corrcoef(ModelCof_evVw_l[:,1,1],gml.gradients_[:,0])[0,1],ls=\"--\", color=\"k\")\n",
    "\n",
    "ax.set_xticks([1, 2, 3])\n",
    "ax.set_xticklabels([\"Random\",\"Mantel\",\"Smoothed Mantel\"])\n",
    "plt.savefig('./imagesAvG/NullCorrGradSill.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.patch.set_alpha(0)\n",
    "data_to_plot = [US2ShuffModelCof_evVw_l[:,:,1,0].std(axis=0), US1ShuffModelCof_evVw_l[:,:,1,0].std(axis=0),ShuffModelCof_evVw_l[:,:,1,0].std(axis=0) ]\n",
    "ax = fig.add_axes([0.1,0.1,0.9,0.9])\n",
    "bp = ax.violinplot(data_to_plot)\n",
    "\n",
    "for pc in bp['bodies']:\n",
    "    pc.set_facecolor('white')\n",
    "    pc.set_edgecolor('black')\n",
    "    \n",
    "for partname in ('cbars','cmins','cmaxes'):\n",
    "    vp = bp[partname]\n",
    "    vp.set_edgecolor('k')\n",
    "    vp.set_linewidth(1)\n",
    "ax.axhline(np.std(ModelCof_evVw_l[:,1,0],axis=0),ls=\"--\", color=\"k\")\n",
    "\n",
    "ax.set_xticks([1, 2,3])\n",
    "ax.set_xticklabels([\"Random\",\"Mantel\",\"Smoothed Mantel\"])\n",
    "plt.savefig('./imagesAvG/NullSTDRange.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.patch.set_alpha(0)\n",
    "data_to_plot = [US2ShuffModelCof_evVw_l[:,:,1,1].std(axis=0), US1ShuffModelCof_evVw_l[:,:,1,1].std(axis=0),ShuffModelCof_evVw_l[:,:,1,1].std(axis=0) ]\n",
    "ax = fig.add_axes([0.1,0.1,0.9,0.9])\n",
    "bp = ax.violinplot(data_to_plot)\n",
    "\n",
    "for pc in bp['bodies']:\n",
    "    pc.set_facecolor('white')\n",
    "    pc.set_edgecolor('black')\n",
    "    \n",
    "for partname in ('cbars','cmins','cmaxes'):\n",
    "    vp = bp[partname]\n",
    "    vp.set_edgecolor('k')\n",
    "    vp.set_linewidth(1)\n",
    "ax.axhline(np.std(ModelCof_evVw_l[:,1,1],axis=0),ls=\"--\", color=\"k\")\n",
    "\n",
    "ax.set_xticks([1, 2,3])\n",
    "ax.set_xticklabels([\"Random\",\"Mantel\",\"Smoothed Mantel\"])\n",
    "\n",
    "plt.savefig('./imagesAvG/NullSTDSill.png')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c4c252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relationship between sill/range and principal gradient for each null and empirical data\n",
    "from brainspace.gradient import GradientMaps\n",
    "from brainspace.gradient import alignment\n",
    "\n",
    "numComp=3\n",
    "\n",
    "#gmr = GradientMaps(n_components=numComp, approach='dm', kernel='normalized_angle')\n",
    "gml = GradientMaps(n_components=numComp,approach='le')\n",
    "\n",
    "gml.fit(EmpFC)\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rc_file_defaults()\n",
    "#print(np.corrcoef(ModelCof_IndWBev_l[:,1,0],ModelCof_IndWBev_l_2[:,1,0]))\n",
    "\n",
    "fig, axs = plt.subplots(1,4,figsize=(18,4))\n",
    "fig.patch.set_alpha(0)\n",
    "#print(stats.spearmanr(ModelCof_IndWBev_l[:,1,0],ModelCof_IndWBev_l_2[:,1,0]))\n",
    "\n",
    "axs[0].scatter(ModelCof_evVw_l[:,1,0],ModelCof_evVw_l[:,1,1],c=gml.gradients_[:,0],cmap='plasma',s=5)\n",
    "axs[0].grid(False)\n",
    "\n",
    "it=10\n",
    "axs[3].scatter(ShuffModelCof_evVw_l[it,:,1,0],ShuffModelCof_evVw_l[it,:,1,1],c=gml.gradients_[:,0],cmap='plasma',s=5)\n",
    "axs[3].grid(False)\n",
    "\n",
    "axs[2].scatter(US1ShuffModelCof_evVw_l[it,:,1,0],US1ShuffModelCof_evVw_l[it,:,1,1],c=gml.gradients_[:,0],cmap='plasma',s=5)\n",
    "axs[2].grid(False)\n",
    "\n",
    "axs[1].scatter(US2ShuffModelCof_evVw_l[it,:,1,0],US2ShuffModelCof_evVw_l[it,:,1,1],c=gml.gradients_[:,0],cmap='plasma',s=5)\n",
    "axs[1].grid(False)\n",
    "\n",
    "plt.savefig('./imagesAvG/NullExample.png')\n",
    "#np.corrcoef(ModelCof_evVw_l[:,2,0],gml.gradients_[:,0])\n",
    "\n",
    "#fig.colorbar(im,ax=axs[1])\n",
    "#plt.savefig('./imagesAvG/RangeSill_Gradient_3.png')\n",
    "\n",
    "#np.corrcoef(ModelCof_evVw_l[:,2,0],gml.gradients_[:,0])\n",
    "\n",
    "\n",
    "#plt.scatter(ModelCof_evVw_l[:,1,0],ModelCof_evVw_l[:,1,1],c=gml.gradients_[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd37cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
